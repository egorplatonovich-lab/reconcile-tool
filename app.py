import streamlit as st
import pandas as pd
import re

# --- PAGE CONFIG (CSS INJECTION FOR UI POLISH) ---
st.set_page_config(page_title="–°–≤–µ—Ä–∫–∞ –î–∞–Ω–Ω—ã—Ö v29", layout="wide", page_icon="‚ú®")

# Custom CSS to make the main button prominent and center it
st.markdown("""
<style>
div.stButton > button:first-child {
    width: 100%;
    height: 3em;
    font-size: 18px;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)


# --- SESSION STATE ---
if 'analysis_done' not in st.session_state: st.session_state['analysis_done'] = False
if 'main_df' not in st.session_state: st.session_state['main_df'] = None
if 'investigation_df' not in st.session_state: st.session_state['investigation_df'] = None

st.title("‚ú® –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –°–≤–µ—Ä–∫–∏ –î–∞–Ω–Ω—ã—Ö (Reconciliation Tool)")
st.markdown("–ü—Ä–æ—Å—Ç–æ–π –∏ —Ç–æ—á–Ω—ã–π —Å–ø–æ—Å–æ–± —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ –æ—Ç—á–µ—Ç–∞ –∏ –Ω–∞–π—Ç–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è.")

# --- HELPER FUNCTIONS (LOGIC UNCHANGED) ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            return pd.read_csv(file, low_memory=False)
        else:
            return pd.read_excel(file)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file.name}: {e}")
        return None

def clean_currency(series):
    if pd.api.types.is_numeric_dtype(series): return series
    return series.astype(str).str.replace(r'[^\d.,-]', '', regex=True).str.replace(',', '.').astype(float)

def clean_string_key(series):
    s = series.astype(str).fillna("")
    s = s.str.strip().str.lower()
    s = s.str.replace(r'\.0$', '', regex=True)
    return s

def clean_compare_string(series):
    return series.astype(str).fillna("").str.strip()

def nuclear_date_parser(val):
    s = str(val).strip()
    s = s.replace('T', ' ').replace('Z', '')
    # ISO
    iso_match = re.search(r'(\d{4}-\d{2}-\d{2})', s)
    if iso_match:
        try: return pd.to_datetime(iso_match.group(1))
        except: pass
    # Euro
    euro_match = re.search(r'(\d{2}\.\d{2}\.\d{4})', s)
    if euro_match:
        try: return pd.to_datetime(euro_match.group(1), dayfirst=True)
        except: pass
    # Fallback
    try: return pd.to_datetime(s, errors='coerce')
    except: return pd.NaT

def find_date_col(cols):
    for c in cols:
        if 'date' in c.lower() or 'time' in c.lower() or 'created' in c.lower() or 'at' in c.lower() or '–¥–∞—Ç–∞' in c.lower():
            return c
    return cols[0]

# ================= UI STEP 1: UPLOAD FILES =================
st.header("üìÇ –®–∞–≥ 1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
st.markdown("–í—ã–±–µ—Ä–∏—Ç–µ –¥–≤–∞ —Ñ–∞–π–ª–∞ (CSV –∏–ª–∏ Excel), –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Å–≤–µ—Ä–∏—Ç—å.")

c1, c2 = st.columns(2)
# Humanized labels and helpful captions
with c1: 
    f1 = st.file_uploader("–ù–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (–∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã)", key="f1", help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã–≥—Ä—É–∑–∫–∞ –∏–∑ –≤–∞—à–µ–π CRM/ERP).")
with c2: 
    f2 = st.file_uploader("–î–∞–Ω–Ω—ã–µ –ø–∞—Ä—Ç–Ω—ë—Ä–∞ (–≤–Ω–µ—à–Ω–∏–π –æ—Ç—á—ë—Ç)", key="f2", help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç –ø–∞—Ä—Ç–Ω–µ—Ä–∞, –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏–ª–∏ –ø–ª–∞—Ç–µ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã.")

# --- DATA LOADING & PREP ---
df1, df2 = None, None
files_ready = False

if f1 and f2:
    df1 = load_data(f1)
    df2 = load_data(f2)
    if df1 is not None and df2 is not None:
        files_ready = True
    else:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ–¥–∏–Ω –∏–∑ —Ñ–∞–π–ª–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç.")

if files_ready:
    st.divider()

    # ================= UI STEP 2: PERIOD & LINKING =================
    st.header("üîó –®–∞–≥ 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–∏–æ–¥–∞ –∏ —Å–≤—è–∑–µ–π")
    st.markdown("–£–∫–∞–∂–∏—Ç–µ, –∑–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ –º—ã —Å–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –∫–∞–∫ —Å–≤—è–∑–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Ñ–∞–π–ª–∞–º–∏.")
    
    # --- A. Period Selection ---
    st.subheader("üìÖ –ü–µ—Ä–∏–æ–¥ —Å–≤–µ—Ä–∫–∏")
    col_per1, col_per2 = st.columns(2)
    with col_per1:
        target_year = st.selectbox("–ì–æ–¥", range(2023, 2030), index=3)
    with col_per2:
        months = {1: "–Ø–Ω–≤–∞—Ä—å", 2: "–§–µ–≤—Ä–∞–ª—å", 3: "–ú–∞—Ä—Ç", 4: "–ê–ø—Ä–µ–ª—å", 5: "–ú–∞–π", 6: "–ò—é–Ω—å", 
                  7: "–ò—é–ª—å", 8: "–ê–≤–≥—É—Å—Ç", 9: "–°–µ–Ω—Ç—è–±—Ä—å", 10: "–û–∫—Ç—è–±—Ä—å", 11: "–ù–æ—è–±—Ä—å", 12: "–î–µ–∫–∞–±—Ä—å"}
        target_month_name = st.selectbox("–ú–µ—Å—è—Ü", list(months.values()))
        target_month = list(months.keys())[list(months.values()).index(target_month_name)]

    st.write("") # Spacer

    # --- B. Columns Mapping ---
    st.subheader("üîë –ö–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
    
    # Auto-detect dates
    idx_d1 = list(df1.columns).index(find_date_col(df1.columns))
    idx_d2 = list(df2.columns).index(find_date_col(df2.columns))

    col_map1, col_map2 = st.columns(2)
    
    # Column Mapping Block 1 (Our Data)
    with col_map1:
        st.markdown("##### üèõÔ∏è –í –ù–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        date_col_1 = st.selectbox("–ì–¥–µ —É–∫–∞–∑–∞–Ω–∞ –¥–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏?", df1.columns, index=idx_d1, help="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.")
        # Humanized "Anchor" label + Tooltip
        key_col_1 = st.selectbox("–ü–æ–ª–µ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID)", df1.columns, help="‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ! –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º (ID –∑–∞–∫–∞–∑–∞, —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏), –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å –≤ –æ–±–æ–∏—Ö —Ñ–∞–π–ª–∞—Ö.")
        if df1[key_col_1].duplicated().any():
             st.warning(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –í —Å—Ç–æ–ª–±—Ü–µ '{key_col_1}' –Ω–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã. –≠—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å.")

    # Column Mapping Block 2 (Provider Data)
    with col_map2:
        st.markdown("##### ü§ù –í –î–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–∞")
        date_col_2 = st.selectbox("–ì–¥–µ —É–∫–∞–∑–∞–Ω–∞ –¥–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏? ", df2.columns, index=idx_d2, help="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π –≤ —Ñ–∞–π–ª–µ –ø–∞—Ä—Ç–Ω–µ—Ä–∞.")
        key_col_2 = st.selectbox("–ü–æ–ª–µ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID) ", df2.columns, help="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü –≤ —Ñ–∞–π–ª–µ –ø–∞—Ä—Ç–Ω–µ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É ID.")
        if df2[key_col_2].duplicated().any():
             st.warning(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –í —Å—Ç–æ–ª–±—Ü–µ '{key_col_2}' –Ω–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã.")

    st.divider()

    # ================= UI STEP 3: COMPARISON FIELDS =================
    st.header("‚öôÔ∏è –®–∞–≥ 3. –ß—Ç–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å?")
    st.markdown("–í—ã–±–µ—Ä–∏—Ç–µ, –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –¥–∞–Ω–Ω—ã–µ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å, –µ—Å–ª–∏ ID —Å–æ–≤–ø–∞–ª–∏.")

    # Using extenders/columns to organize checks clearly
    
    # 1. Price Check
    use_price = st.checkbox("üí∞ –°–≤–µ—Ä—è—Ç—å –°—É–º–º—É/–¶–µ–Ω—É", value=True, help="–°—Ä–∞–≤–Ω–∏—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")
    p_col_1, p_col_2 = None, None
    if use_price:
        pc1, pc2 = st.columns(2)
        with pc1: p_col_1 = st.selectbox("–°—Ç–æ–ª–±–µ—Ü —Å —Å—É–º–º–æ–π (–£ –Ω–∞—Å)", df1.columns, key="p1")
        with pc2: p_col_2 = st.selectbox("–°—Ç–æ–ª–±–µ—Ü —Å —Å—É–º–º–æ–π (–£ –ø–∞—Ä—Ç–Ω—ë—Ä–∞)", df2.columns, key="p2")
    
    st.write("") # Spacer

    # 2. User/Text Check
    use_var_a = st.checkbox("üë§ –°–≤–µ—Ä—è—Ç—å –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è / –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –ê", value=False, help="–°—Ä–∞–≤–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Email –∫–ª–∏–µ–Ω—Ç–∞ –∏–ª–∏ ID –º–µ–Ω–µ–¥–∂–µ—Ä–∞).")
    va_col_1, va_col_2 = None, None
    if use_var_a:
        vc1, vc2 = st.columns(2)
        with vc1: va_col_1 = st.selectbox("–¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ (–£ –Ω–∞—Å)", df1.columns, key="va1")
        with vc2: va_col_2 = st.selectbox("–¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ (–£ –ø–∞—Ä—Ç–Ω—ë—Ä–∞)", df2.columns, key="va2")

    st.write("") # Spacer

    # 3. Additional Check
    use_var_b = st.checkbox("üß© –°–≤–µ—Ä—è—Ç—å –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –ë (–Ω–∞–ø—Ä–∏–º–µ—Ä, –°—Ç–∞—Ç—É—Å)", value=False, help="–°—Ä–∞–≤–Ω–∏—Ç—å –µ—â–µ –æ–¥–Ω–æ –ø–æ–ª–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞).")
    vb_col_1, vb_col_2 = None, None
    add_field_name = "–î–æ–ø. –ø–æ–ª–µ" 
    if use_var_b:
        vb1, vb2 = st.columns(2)
        with vb1: vb_col_1 = st.selectbox("–î–æ–ø. –ø–æ–ª–µ (–£ –Ω–∞—Å)", df1.columns, key="vb1")
        with vb2: vb_col_2 = st.selectbox("–î–æ–ø. –ø–æ–ª–µ (–£ –ø–∞—Ä—Ç–Ω—ë—Ä–∞)", df2.columns, key="vb2")
        add_field_name = vb_col_1 # Dynamic name capture

    st.divider()

    # ================= UI STEP 4: RUN ACTION =================
    
    # Readiness Checklist (Micro-feedback)
    st.markdown("#### –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å–≤–µ—Ä–∫–µ:")
    ready_col1, ready_col2, ready_col3 = st.columns(3)
    with ready_col1: st.write("‚úÖ –§–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    with ready_col2: st.write(f"‚úÖ –ü–µ—Ä–∏–æ–¥: {target_month_name} {target_year}")
    with ready_col3: st.write(f"‚úÖ –°–≤—è–∑—å –ø–æ ID –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")

    st.write("") # Extra space before big button
    
    # Centered, Prominent Button (Styled via CSS at the top)
    b_c1, b_c2, b_c3 = st.columns([1, 2, 1])
    with b_c2:
        run_pressed = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–µ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö", type="primary")

    if run_pressed:
        with st.spinner("‚è≥ –ò–¥—ë—Ç –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."):
            # --- LOGIC START (SAME AS v28) ---
            
            # 1. PARSE DATES
            df1['_date_obj'] = df1[date_col_1].apply(nuclear_date_parser)
            df2['_date_obj'] = df2[date_col_2].apply(nuclear_date_parser)
            
            if df1['_date_obj'].notna().sum() == 0:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—ã –≤ –≤–∞—à–µ–º —Ñ–∞–π–ª–µ (—Å—Ç–æ–ª–±–µ—Ü '{date_col_1}').")
                st.stop()
            if df2['_date_obj'].notna().sum() == 0:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—ã –≤ —Ñ–∞–π–ª–µ –ø–∞—Ä—Ç–Ω—ë—Ä–∞ (—Å—Ç–æ–ª–±–µ—Ü '{date_col_2}').")
                st.stop()

            # 2. PREPARE DATA
            data1 = pd.DataFrame()
            data2 = pd.DataFrame()
            
            data1['_anchor'] = clean_string_key(df1[key_col_1])
            data2['_anchor'] = clean_string_key(df2[key_col_2])
            
            data1['ID_OUR'] = df1[key_col_1].astype(str)
            data2['ID_PROV'] = df2[key_col_2].astype(str)
            data1['Date_OUR'] = df1['_date_obj']
            data2['Date_PROV'] = df2['_date_obj']

            if use_price:
                data1['Price_1'] = clean_currency(df1[p_col_1])
                data2['Price_2'] = clean_currency(df2[p_col_2])
            if use_var_a:
                data1['User_1'] = clean_compare_string(df1[va_col_1])
                data2['User_2'] = clean_compare_string(df2[va_col_2])
            if use_var_b:
                data1['Add_1'] = clean_compare_string(df1[vb_col_1])
                data2['Add_2'] = clean_compare_string(df2[vb_col_2])

            # 3. GLOBAL MERGE
            full_merge = pd.merge(data1, data2, on='_anchor', how='outer', indicator=True)

            # 4. FILTERING
            def check_month(dt):
                if pd.isna(dt): return False
                return (dt.month == target_month) and (dt.year == target_year)

            full_merge['In_Month_OUR'] = full_merge['Date_OUR'].apply(check_month)
            full_merge['In_Month_PROV'] = full_merge['Date_PROV'].apply(check_month)

            main_mask = full_merge['In_Month_OUR'] | full_merge['In_Month_PROV']
            df_main = full_merge[main_mask].copy()

            # 5. ANALYZE MAIN (MATRIX LOGIC)
            if use_price:
                df_main['Diff'] = (df_main['Price_1'].fillna(0) - df_main['Price_2'].fillna(0)).round(2)

            def analyze_row_matrix(row):
                res = {
                    'Status_Exist': 'OK',
                    'Status_Price': '',
                    'Status_User': '',
                    f'Status_{add_field_name}': ''
                }
                
                loc_our = row['In_Month_OUR']
                loc_prov = row['In_Month_PROV']
                global_merge = row['_merge']
                
                # --- 1. EXISTENCE CHECK ---
                is_present_globally = False
                
                if loc_our and not loc_prov:
                    if global_merge == 'left_only':
                        res['Status_Exist'] = '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É –ø–∞—Ä—Ç–Ω—ë—Ä–∞ (–í–æ–æ–±—â–µ)'
                        return pd.Series(res)
                    else:
                        res['Status_Exist'] = 'üìÖ –ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞ (–ù–∞–π–¥–µ–Ω–æ —É –ø–∞—Ä—Ç–Ω—ë—Ä–∞ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—è—Ü–µ)'
                        is_present_globally = True

                elif not loc_our and loc_prov:
                    if global_merge == 'right_only':
                        res['Status_Exist'] = '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É –Ω–∞—Å (–í–æ–æ–±—â–µ)'
                        return pd.Series(res)
                    else:
                        res['Status_Exist'] = 'üìÖ –ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞ (–ù–∞–π–¥–µ–Ω–æ —É –Ω–∞—Å –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—è—Ü–µ)'
                        is_present_globally = True
                
                else:
                    is_present_globally = True

                # --- 2. CONTENT CHECK ---
                if is_present_globally:
                    if use_price:
                        p1 = float(row['Price_1']) if pd.notnull(row['Price_1']) else 0.0
                        p2 = float(row['Price_2']) if pd.notnull(row['Price_2']) else 0.0
                        if abs(p1 - p2) > 0.01:
                            res['Status_Price'] = '–û—à–∏–±–∫–∞ –≤ —Å—É–º–º–µ'
                        else:
                            res['Status_Price'] = 'OK'
                    
                    if use_var_a:
                        if str(row['User_1']) != str(row['User_2']):
                            res['Status_User'] = '–û—à–∏–±–∫–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –ø–æ–ª–µ –ê'
                        else:
                            res['Status_User'] = 'OK'

                    if use_var_b:
                        if str(row['Add_1']) != str(row['Add_2']):
                            res[f'Status_{add_field_name}'] = f'–û—à–∏–±–∫–∞ –≤ –ø–æ–ª–µ "{add_field_name}"'
                        else:
                            res[f'Status_{add_field_name}'] = 'OK'

                return pd.Series(res)

            status_cols = df_main.apply(analyze_row_matrix, axis=1)
            df_main = pd.concat([df_main, status_cols], axis=1)

            def is_dirty(row):
                if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç' in row['Status_Exist']: return True
                if '–ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞' in row['Status_Exist']: return True
                if use_price and '–û—à–∏–±–∫–∞' in str(row.get('Status_Price', '')): return True
                if use_var_a and '–û—à–∏–±–∫–∞' in str(row.get('Status_User', '')): return True
                if use_var_b and '–û—à–∏–±–∫–∞' in str(row.get(f'Status_{add_field_name}', '')): return True
                return False

            df_main['Is_Error'] = df_main.apply(is_dirty, axis=1)
            st.session_state['main_df'] = df_main
            
            # Investigation Logic (Humanized)
            df_investigation = df_main[df_main['Status_Exist'].str.contains('–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç') | df_main['Status_Exist'].str.contains('–ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞')].copy()
            
            def investigate_row(row):
                status = row['Status_Exist']
                s_prov = row['Date_PROV'].strftime('%d.%m.%Y') if pd.notnull(row['Date_PROV']) else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                s_our = row['Date_OUR'].strftime('%d.%m.%Y') if pd.notnull(row['Date_OUR']) else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

                if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É –ø–∞—Ä—Ç–Ω—ë—Ä–∞' in status: return "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ –ø–∞—Ä—Ç–Ω—ë—Ä–∞"
                if '–ù–∞–π–¥–µ–Ω–æ —É –ø–∞—Ä—Ç–Ω—ë—Ä–∞' in status: return f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É –ø–∞—Ä—Ç–Ω—ë—Ä–∞, –¥–∞—Ç–∞: {s_prov}"
                
                if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É –Ω–∞—Å' in status: return "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –Ω–∞—à–µ–º —Ñ–∞–π–ª–µ"
                if '–ù–∞–π–¥–µ–Ω–æ —É –Ω–∞—Å' in status: return f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É –Ω–∞—Å, –¥–∞—Ç–∞: {s_our}"
                return ""

            if not df_investigation.empty:
                df_investigation['Investigation'] = df_investigation.apply(investigate_row, axis=1)
            
            st.session_state['investigation_df'] = df_investigation
            st.session_state['analysis_done'] = True
            # --- LOGIC END ---

# ================= RESULTS DISPLAY (HUMANIZED) =================
if st.session_state['analysis_done']:
    st.divider()
    df_main = st.session_state['main_df']
    df_inv = st.session_state['investigation_df']
    
    # Styling (Humanized friendly colors)
    def color_cells(val):
        s = str(val)
        if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç' in s: return 'color: #d32f2f; font-weight: bold;' # Red
        if '–ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞' in s: return 'color: #e65100; font-weight: bold;' # Orangeish
        if '–û—à–∏–±–∫–∞' in s: return 'color: #d32f2f; font-weight: bold;' # Red
        if s == 'OK': return 'color: #2e7d32; font-weight: bold;' # Green
        return ''

    def color_none(val): return 'color: #9e9e9e; font-style: italic;' if str(val) == "None" else '' # Grey italic for missing values

    st.header(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–≤–µ—Ä–∫–∏: {target_month_name} {target_year}")
    
    if not df_main.empty:
        discrepancies = df_main[df_main['Is_Error'] == True]
        
        # Metrics (Humanized labels)
        total_cnt = len(df_main)
        truly_missing = df_main['Status_Exist'].str.contains('–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç').sum()
        date_cutoff = df_main['Status_Exist'].str.contains('–ù–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –¥–∞—Ç–∞').sum()
        
        price_cnt = 0
        net_diff = 0.0
        if use_price:
            price_errs = discrepancies[discrepancies['Status_Price'] == '–û—à–∏–±–∫–∞ –≤ —Å—É–º–º–µ']
            price_cnt = len(price_errs)
            net_diff = price_errs['Diff'].sum()
        
        content_cnt = 0
        if use_var_a: content_cnt += discrepancies['Status_User'].str.contains('–û—à–∏–±–∫–∞').sum()
        if use_var_b: content_cnt += discrepancies[f'Status_{add_field_name}'].str.contains('–û—à–∏–±–∫–∞').sum()

        # Display Metrics
        m1, m2, m3, m4, m5 = st.columns(5)
        m1.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ (–≤ –ø–µ—Ä–∏–æ–¥–µ)", total_cnt)
        m2.metric("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (–í–æ–æ–±—â–µ)", truly_missing, delta_color="inverse")
        m3.metric("üìÖ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –¥–∞—Ç", date_cutoff, delta_color="off")
        if use_price: m4.metric("–û—à–∏–±–∫–∏ –≤ —Å—É–º–º–µ", price_cnt, delta=f"–†–∞–∑–Ω–∏—Ü–∞: {net_diff:,.2f}")
        else: m4.metric("–û—à–∏–±–∫–∏ –≤ —Å—É–º–º–µ", "–ù–µ –ø—Ä–æ–≤–µ—Ä—è–ª–æ—Å—å")
        m5.metric("–ü—Ä–æ—á–∏–µ –æ—à–∏–±–∫–∏", content_cnt, delta_color="inverse")

        # Table Controls
        c_view, c_down = st.columns([1, 3])
        with c_view: show_all = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ (–≤–∫–ª—é—á–∞—è —Å–æ–≤–ø–∞–≤—à–∏–µ)", value=False)
        
        view_main = df_main.copy() if show_all else discrepancies.copy()
        
        if not view_main.empty:
            view_main['Date_OUR_Str'] = view_main['Date_OUR'].dt.strftime('%d.%m.%Y').fillna("None")
            view_main['Date_PROV_Str'] = view_main['Date_PROV'].dt.strftime('%d.%m.%Y').fillna("None")
            
            # Dynamic Columns with friendly names
            cols = ['ID_OUR', 'ID_PROV', 'Date_OUR_Str', 'Date_PROV_Str']
            renames = {'Date_OUR_Str': '–î–∞—Ç–∞ (–ù–∞—à–∏)', 'Date_PROV_Str': '–î–∞—Ç–∞ (–ü–∞—Ä—Ç–Ω—ë—Ä)', 'Status_Exist': '–°—Ç–∞—Ç—É—Å (–ù–∞–ª–∏—á–∏–µ)'}
            
            cols.append('Status_Exist')

            if use_price: 
                cols.extend(['Price_1', 'Price_2', 'Diff', 'Status_Price'])
                renames.update({'Price_1': '–°—É–º–º–∞ (–ù–∞—à–∏)', 'Price_2': '–°—É–º–º–∞ (–ü–∞—Ä—Ç–Ω—ë—Ä)', 'Diff': '–†–∞–∑–Ω–∏—Ü–∞', 'Status_Price': '–°—Ç–∞—Ç—É—Å (–°—É–º–º–∞)'})
            
            if use_var_a: 
                cols.extend(['User_1', 'User_2', 'Status_User'])
                renames.update({'User_1': f"{va_col_1} (–ù–∞—à–∏)", 'User_2': f"{va_col_2} (–ü–∞—Ä—Ç–Ω—ë—Ä)", 'Status_User': '–°—Ç–∞—Ç—É—Å (–¢–µ–∫—Å—Ç –ê)'})
            
            if use_var_b:
                col_stat_dyn = f'Status_{add_field_name}'
                cols.extend(['Add_1', 'Add_2', col_stat_dyn])
                renames.update({'Add_1': f"{vb_col_1} (–ù–∞—à–∏)", 'Add_2': f"{vb_col_2} (–ü–∞—Ä—Ç–Ω—ë—Ä)", col_stat_dyn: f'–°—Ç–∞—Ç—É—Å ({add_field_name})'})
            
            with c_down:
                csv_main = view_main[cols].rename(columns=renames).to_csv(index=False).encode('utf-8')
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç (CSV)", csv_main, "main_report.csv", "text/csv", type="primary")

            st.dataframe(
                view_main[cols].rename(columns=renames).fillna("None").style.map(color_none).map(color_cells),
                use_container_width=True, hide_index=True
            )
        else:
            if show_all: st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            else: st.success("üéâ –û—Ç–ª–∏—á–Ω–æ! –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    else:
        st.warning(f"–í –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ ({target_month_name} {target_year}) —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

    st.divider()

    # Investigation Table (Humanized headers)
    st.header("üïµÔ∏è –†–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (–ü–æ–∏—Å–∫ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö)")
    st.markdown("–ó–¥–µ—Å—å –ø–æ–∫–∞–∑–∞–Ω—ã –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞—à–ª–∏—Å—å –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –º–µ—Å—è—Ü–µ, –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ö –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º—É —Ñ–∞–π–ª—É.")
    if not df_inv.empty:
        cols_inv = ['ID_OUR', 'ID_PROV', 'Investigation', 'Status_Exist']
        
        df_inv['Date_OUR_Str'] = df_inv['Date_OUR'].dt.strftime('%d.%m.%Y').fillna("Unknown")
        df_inv['Date_PROV_Str'] = df_inv['Date_PROV'].dt.strftime('%d.%m.%Y').fillna("Unknown")
        
        cols_inv.insert(1, 'Date_OUR_Str')
        cols_inv.insert(3, 'Date_PROV_Str')
        
        renames_inv = {
            'ID_OUR': 'ID (–ù–∞—à–∏)', 'ID_PROV': 'ID (–ü–∞—Ä—Ç–Ω—ë—Ä)',
            'Date_OUR_Str': '–î–∞—Ç–∞ (–ù–∞—à–∏)', 'Date_PROV_Str': '–î–∞—Ç–∞ (–ü–∞—Ä—Ç–Ω—ë—Ä)', 
            'Investigation': '–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞', 'Status_Exist': '–ò—Å—Ö–æ–¥–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞'
        }

        def color_res(val):
            if '‚úÖ' in str(val): return 'color: #2e7d32; font-weight: bold;'
            if '‚ùå' in str(val): return 'color: #d32f2f; font-weight: bold;'
            return ''

        csv_inv = df_inv[cols_inv].rename(columns=renames_inv).to_csv(index=False).encode('utf-8')
        st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (CSV)", csv_inv, "investigation_report.csv", "text/csv")

        st.dataframe(df_inv[cols_inv].rename(columns=renames_inv).fillna("None").style.map(color_res, subset=['–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞']), use_container_width=True, hide_index=True)
    else:
        st.success("–†–∞—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ (–≤—Å–µ –∑–∞–ø–∏—Å–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ü–µ–ª–µ–≤–æ–º –º–µ—Å—è—Ü–µ).")
elif files_ready:
    # Hint to press the button
    st.info("üëÜ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã—à–µ –∏ –Ω–∞–∂–º–∏—Ç–µ –±–æ–ª—å—à—É—é –∫–Ω–æ–ø–∫—É '–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–µ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö'.")
else:
    # Initial state hint
    st.info("üëà –ù–∞—á–Ω–∏—Ç–µ —Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –≤ –®–∞–≥–µ 1.")
